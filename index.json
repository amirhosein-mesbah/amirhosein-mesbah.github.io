
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["amir-mesbah"],"categories":null,"content":"Welcome! I am a master‚Äôs student of Artificial intelligence and a Junior Research Assistant at the Cognitive Systems lab at the school of ECE at the University of Tehran. I completed my BA in Computer Engineering at the University of Tabriz (ECE faculty). My interests in machine learning and computer science began through many fun experiences working with computer in childhood.\nMy research focuses on enabling RL agents to find Bottleneck states in the Environment faster and use the benefit of social learning during their learning procces like humans and social animals. I‚Äôve been fortunate to have many wonderful supervisors on this topics, including Dr. Majid Nili Ahamdabadi, Dr. Reshad Hosseini and Dr. Pooya Shariatpanahi.\nDownload my resum√©.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3fd1a8370ab3cb3e039aa18894f3a895","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Welcome! I am a master‚Äôs student of Artificial intelligence and a Junior Research Assistant at the Cognitive Systems lab at the school of ECE at the University of Tehran. I completed my BA in Computer Engineering at the University of Tabriz (ECE faculty).","tags":null,"title":"Amir Mesbah","type":"authors"},{"authors":null,"categories":null,"content":"üëã Welcome to the Academic Template The Wowchemy Academic Resum√© Template for Hugo empowers you to create your job-winning online resum√© and showcase your academic publications.\nCheck out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase.\nWowchemy makes it easy to create a beautiful website for free. Edit your site in Markdown, Jupyter, or RStudio (via Blogdown), generate it with Hugo, and deploy with GitHub or Netlify. Customize anything on your site with widgets, themes, and language packs.\nüëâ Get Started üìö View the documentation üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Guide and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to unlock rewards with sponsorship You‚Äôre looking at a Wowchemy widget This homepage section is an example of adding elements to the Blank widget.\nBackgrounds can be applied to any section. Here, the background option is set give a color gradient.\nTo remove this section, delete content/home/demo.md.\nGet inspired Check out the Markdown files which power the Academic Demo, or view the showcase.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1d1825344e8f4b25c2137e0a9c8b655f","permalink":"https://amirhosein-mesbah.github.io/home-unused/demo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/demo/","section":"home-unused","summary":"üëã Welcome to the Academic Template The Wowchemy Academic Resum√© Template for Hugo empowers you to create your job-winning online resum√© and showcase your academic publications.\nCheck out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase.","tags":null,"title":"Academic Template","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4a7e3501655fed0a4b0ce814e15ff2c9","permalink":"https://amirhosein-mesbah.github.io/home-unused/skills/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/skills/","section":"home-unused","summary":"","tags":null,"title":"Skills","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9e909a8894fd21a2eff4b3e43238d81e","permalink":"https://amirhosein-mesbah.github.io/home-unused/accomplishments/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/accomplishments/","section":"home-unused","summary":"","tags":null,"title":"Accomplish\u0026shy;ments","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0e643989bdefe366f2b5fddf949a36b6","permalink":"https://amirhosein-mesbah.github.io/home-unused/posts/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/posts/","section":"home-unused","summary":"","tags":null,"title":"Recent Posts","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d927b251d3da15a737d1f66fb88d4504","permalink":"https://amirhosein-mesbah.github.io/home-unused/talks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/talks/","section":"home-unused","summary":"","tags":null,"title":"Recent \u0026 Upcoming Talks","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"28f54f6e819207239a6024bbaa9d78de","permalink":"https://amirhosein-mesbah.github.io/home-unused/featured/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/featured/","section":"home-unused","summary":"","tags":null,"title":"Featured Publications","type":"home-unused"},{"authors":null,"categories":null,"content":" Quickly discover relevant content by filtering publications. ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"19cfbeefa99b41865496b68f2fb35bad","permalink":"https://amirhosein-mesbah.github.io/home-unused/publications/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/publications/","section":"home-unused","summary":" Quickly discover relevant content by filtering publications. ","tags":null,"title":"Recent Publications","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"657179738bed56748434d6ae76e8a647","permalink":"https://amirhosein-mesbah.github.io/home-unused/tags/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/tags/","section":"home-unused","summary":"","tags":null,"title":"Popular Topics","type":"home-unused"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy‚Äôs Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://amirhosein-mesbah.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":null,"categories":null,"content":"This Project is a Pytorch Implementation of a paper entitled ‚ÄúGossip training for deep learning‚Äù by Michael Blot et al which proposed a distributed method for training deep learning networks.\nI‚Äôve used the Gossip training method for a multilabel classification task\nDataset For implementing gossip training I chose fashion MNIST for training and evaluation of networks. Images of this dataset are gray-level images in 10 classes as described below:\n0: T-shirt/top, 1: Trouser, 2: Pullover, 3: Dress, 4: Coat, 5: Sandal, 6: Shirt, 7: Sneaker, 8: Bag, 9: Ankle boot\nAs a preprocessing step, before Training the networks I normalized the images.\nTraining I‚Äôve implemented different Configurations of Gossip training to investigate the role of probability parameters, Communication matrix, and the kind of communication graph.\ndifferent models are listed below:\ncentralized model Gossip training Gossip training for different values of parameter p as the probability of communication Gossip training for different communication matrices Random Matrix Double Random Matix The matrix variates with time Gossip training for Different Communication graphs strongly connected periodically strongly connected Below you can see loss and accuracy during training for different amounts of parameter p:\nLoss during training loss Accuracy during training Accuracy Results Results for different values of parameter p are in the below table\nParameter p Accuracy% 1 87,14 0.5 87,29 0.2 87,25 0.1 86,45 Results for different Communication matrices are as below\ncommunication matrix Accuracy% Random 90,98 Double Random 90,56 Varying with time 86,94 Results for different Communication graphs are as below\ncommunication graph Accuracy% Periodically strongly connected 89,18 Strongly connected 89,81 ","date":1633824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633824000,"objectID":"f1ba23413892c640f63ec27dff4e11d5","permalink":"https://amirhosein-mesbah.github.io/project/distributed_dl/","publishdate":"2021-10-10T00:00:00Z","relpermalink":"/project/distributed_dl/","section":"project","summary":"Training multiple Deep Neural Networks which they can communicate.","tags":["Deep Learning","past"],"title":"Distributed Gossip training for Fashion MNIST classification","type":"project"},{"authors":null,"categories":null,"content":"In this project, I‚Äôve Implemented a grid environment with 2 agents and 2 goal states. The agents have to learn to reach the goal states by receiving the maximum reward and avoiding obstacles. The environment is shown below\nEnvironment Elements of Environment:\nAgents: Blue Squares Obstacles: Red Squares Goal States: Green Squares Training After training each agent lonely with the sarsa algorithm, I implemented several distributed algorithms like:\nDistributed On-Policy algorithms like SARSA Min-Max Q-Learning Belief Based Algorithm Distributed Actor-Critic Results The average Reward during the learning episodes for SARSA, Min-Max Q-Learning, and Belief-Based learning is shown Below:\nAverage Reward during the learning episodes for SARSA Average reward for SARSA Average Reward during the learning episodes for SARSA Average reward for Distributed SARSA Average Reward during the learning episodes for Min-Max Q-Learning Average reward for Min-Max Q-Learning Average Reward during the learning episodes for Belief Based Algorithms Average reward for Belief Based Algorithms ","date":1633824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633824000,"objectID":"7681aaf5c20bb5647363612abb69eb50","permalink":"https://amirhosein-mesbah.github.io/project/distributed_rl/","publishdate":"2021-10-10T00:00:00Z","relpermalink":"/project/distributed_rl/","section":"project","summary":"Implementing Distributed algorithms for multi agent Reinforcement Learning.","tags":["Reinforcement Learning","past"],"title":"Multi‚ÄëAgent Distributed Reinforcement Learning for grid Environment","type":"project"},{"authors":["admin","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It‚Äôs a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy‚Äôs future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://amirhosein-mesbah.github.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://amirhosein-mesbah.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["admin","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"ff6a19061a984819d30c916886db56ef","permalink":"https://amirhosein-mesbah.github.io/publication/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/example/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"Electroencephalogram EEgLab toolbox in Matlab I‚Äôve used EEgLab toolBox in Matlab for preprocessing EEG data:\nResampling Re‚Äëreferencing baseline normalization creating epochs Representational Dissimilarity Matrices (RDM) Analysis checking for the dissimilarity of brain state in the IT cortex for three different stimulus. RSA diagram is shown below\nRSA As shown in the Figure above, at the time of 200 milliseconds, the graphs of all 3 stimuli overlap and these 3 stimuli cannot be distinguished from each other. So 200 milliseconds is not a good time to distinguish between 3 stimuli. According to the course materials and the class, cognition occurs in the IT cortex between 00 and 600 milliseconds. Therefore, according to the graph of this interval, it can be a good interval for distinguishing between 3 stimuli. Also, considering that the input image does not reach the IT cortex until 150 milliseconds, it can be seen in the diagram that from the beginning of time until about 150 milliseconds, the diagrams of the 3 stimuli overlap to a large extent.\nLocal Field Potentials Phase Lock Analysis In this part, we investigate phase locking between two areas of v4 and EFE in the IT Cortex. PLV In the delta, theta, and alpha ranges, we have phase lock in approximately 2300 milliseconds, 1650 milliseconds, and 1300 milliseconds respectively. According to Figure 13, which shows the memory-guided saccade task, these phase-locks can be related to the cue phase. That is, when showing the stimulus to the subject, the v4 and efe regions are phase-locked together.\nGrager Casualty Checking for connectivity between v4 and ECE fMRI Seed‚Äëbased Correlation Analysis on fMRI data modality to find significant voxels ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1816c21f51f43464dc446ff335c0ebe2","permalink":"https://amirhosein-mesbah.github.io/project/continuous_time/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/continuous_time/","section":"project","summary":"several analysis like RDM, PLV, Granger casuality are done on multiple data modalities.","tags":["Neuroscience","past"],"title":"Analysing Continuous‚ÄëTime Neural Signals for different data modalities","type":"project"},{"authors":null,"categories":null,"content":"In this project, I‚Äôve worked on Signle Cell data. Spike Sorting, Unit-based Decoding and Population-based decoding are the three tasks that have been done in this project.\nSpike Sorting After Applying butterworth highpass filter on raw data, we need to calculate threshold for detecting peaks and after extracting peaks and applying PCA for Dimensionality Reduction we use K-Means algorithm for clustering.\nBelow there is a PairPlot for K-means Algorithm for 9 proposed clusters\npairplot Unit-Based Decoding Raster Plots PSTH Firing Rate Mutual Information A sample of raster plot is shown below\npairplot According to this neuron, showing the stimulus to the subject and encoding it happens in approximately 3000 bases. According to the task, it has been pointed out that the encoding interval is between 3050 and 3200, and this indicates that the raster plot is correct for these neurons. In the same way, the approximate range of 5400 to 5600 is related to memory and the approximate range of 6500 to 6650 is also related to the saccade stage.\nPopulation-Based Decoding Use Machine Learning techniques like SVM to Predict and decode neurons performance. The figure below shows recall for each angle over time with a window of 100 and stride\nrecall ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d306a9c79bf829c116c109f537bd0915","permalink":"https://amirhosein-mesbah.github.io/project/discrete_time/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/discrete_time/","section":"project","summary":"Spike Sorting, Unit-based decoding and population based decoding on single cell data.","tags":["Neuroscience","past"],"title":"Analysing Discrete‚ÄëTime Neural Signals","type":"project"},{"authors":null,"categories":null,"content":"In this project, I‚Äôve used the collected data from Psychopy Task, and several analyses have been done on this data.\nCleaning the Data Correcting Column names scaling reaction times handling NaN values removing outliers Exploring the Data looking for correlation and relation of each pair of features Prediction of Behavioral Characteristics looking any relation between reaction time and other features looking any relation between accuracy and other features Psychometric Fitting fit psychometic functions for location, visual field and Eccentricity as a variable\npsychometic function for location of one of the subjects is shown below: psychometic Spread of PSEs Statistical Test to check if PSEs for different location, visual field and Eccentricity are independent Reaction Time Correlation to Choice Complexity Check the relationship between reaction time and handness of each subject Representational Similarity Analysis (RSA) check similarity of PSEs for location, visual field and Eccentricity RSA for `location is shown below\nlocation RSA ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"14365bbe1489cae450a870c456721ce7","permalink":"https://amirhosein-mesbah.github.io/project/behavioral_analysis/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/behavioral_analysis/","section":"project","summary":"Several Behavioral Analysis to find out relationships between features of collected data from a psychopy task.","tags":["Neuroscience","past"],"title":"Behavioral Analysis of subjects by designing a Psychopy task and analyzing the results","type":"project"},{"authors":null,"categories":null,"content":"In this project, I implemented a real-time data pipeline for crypto information and news about crypto which is crawled from this website. I‚Äôve used docker for running bigdata tools like HDFS, airflow, Kafka, Elasticsearch and Kibana on a virtual container flow of data in this pipeline is shown in the below image\nflow of data This Project contains three main Parts:\nPart1: In this Part, with the help of Apache Airflow, I crawled news and information about each crypto in defined time intervals. after preprocessing and cleaning downloaded data for each time interval, I designed an other dag in airflow for merging data of multiple intervals and saving them in HDFS, and also entering the data into the Kafka channel.\nPart2: All of Part 2 was about Apache Kafka. In this part, we have 3 different Kafka channels with their own producers and consumers. The channels are as follows:\nData channel: data is written in this channel by airflow. Preprocess channel: data cleaning is done in this channel and data is sent to elasticsearch. Statics channel: future statics analysis is done in this channel. writing and reading data in Kafka is done by the kafka-python library in python.\nPart 3 Saving data in elastic search and visualizing statistics using Kibana were the goals of this part. After saving data in Elasticsearch by elastticsearch library of python, I applied several visualization graphs with the help of Kibana and finally use them to design a live dashboard in Kibana. The dashboarded is in Persian language due to Persian data and is shown in the below image\ndashboard ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2edcf3fa5109ff2105d4cdae5e1dff77","permalink":"https://amirhosein-mesbah.github.io/project/realtime_data_pipeline/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/realtime_data_pipeline/","section":"project","summary":"Using BigData tools like Apache airflow, Apache Kafka, HDFS, Elasticsearch and kibana to build a real-time data pipeline.","tags":["BigData","past"],"title":"Building a data pipeline on the Crypto market","type":"project"},{"authors":null,"categories":null,"content":"Crowd counting or crowd estimating is a technique used to count or estimate the number of people in a crowd (Wikipedia). Nowadays with help of Deep Learning, we can do this task with neural networks from an image. In this project I implemented model of paper entitled ‚ÄúTowards Perspective-Free Object Counting with Deep Learning‚Äù by Daniel OÀúnoro-Rubio et al.\nPreprocess: after resizing and rescaling the coordinates of each point in the image and applyin a gussain filter in each coordination, the data is ready for training a neural network. below is a sample of training data:\ntrain data sample Training I use ADAM Optimizer for training network and power 2 of norm1 distatnce as loss function. Due to the small amount of data, augmentation methods have also been used to increase the data. The process of changing the value of the Loss function is available below loss of network during training Results Below is the result of traning proposed network with data augmentation output of network ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e699711d8802c1cd2cfe5352cbfab416","permalink":"https://amirhosein-mesbah.github.io/project/crowd_counting/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/crowd_counting/","section":"project","summary":"Counting number of people in crowded images using Deep Learning.","tags":["Deep Learning","past"],"title":"Crowed Counting with Deep Learning","type":"project"},{"authors":null,"categories":null,"content":"Decription: This Project is a group work with Zahra Habibzadeh. in this project we used signals of speech data for a binary classification task to check if the person to whom the sound belongs has Parkinson‚Äôs disease or not.\nThe data used in this project is related to an article with the following title from Jefferson S.Almeida et al:\n‚ÄúDetecting Parkinson‚Äôs disease with sustained phonation and speech signals using machine learning techniques‚Äù\nWe implemented the methods used in this paper for data preprocessing, dimensionality reduction and model training. Also, in addition to these cases, we also used ensemble models for training and better performance.\nResult: The best performance was related to the ensemble model using KNN algorithm, whose accuracy was equal to 96,10%. The results of the rest of the models are available in the table below.\nAlgorithms Accuracy% Logistic regression 87,23 SVM 93,97 Decision Tree 84,04 KNN(K=1) 94,33 MLP 91,84 RBF 93,26 Ensemble 96,10 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0ff6a66c364a579a47a50b40b5e3cdc2","permalink":"https://amirhosein-mesbah.github.io/project/parkinson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/parkinson/","section":"project","summary":"Use ML Algorithms for a parkinson detction task.","tags":["Deep Learning","past"],"title":"Detecting Parkinson disease using signals of speech data with ensemble learning","type":"project"},{"authors":null,"categories":null,"content":"Federated Learning is one of the new eras of Deep Learning whose aim is to train a global Network with respect to private local networks. Leaning on smartphones and medical tasks are some of the important applications of Federated learning.\nIn this Project, I‚Äôve used federated learning for Image segmentation of Autonomous Driving cars data. We can consider a network of each car as a private and local network and we want to train a global network to be robust against perturbations. This project is a Pytorch Implementation of two papers\n‚ÄúFEDERATED OPTIMIZATION IN HETEROGENEOUS NETWORKS‚Äù by Tian Li et al introduces the FedADMM algorithm for aggregation of weights of local networks ‚ÄúCommunication-Efficient Learning of Deep Networks from Decentralized Data‚Äù by H. Brendan McMahan et al introduces Federate learning for the first time and uses the average aggregation method. Data I‚Äôve divided Camvid Dataset which is a famous dataset for segmentation, for each local network and local networks datasets are Non-IID.\nModel For the segmentation task, I‚Äôve used SegNet. we have multiple local SegNet Networks for each Autonomous car and a Global Network for Aggregating weights of local networks. All of the Networks have the same Architecture.\nBelow Loss function of Both Aggregation methods are shown:\nLoss function of Average Aggregation during communication rounds for 3 local networks and one global network average loss Loss function of ADMM Aggregation (FedADMM) during communication rounds for 2 local networks and one global network admm loss Results Some of the segmented images with the fedADMM aggregation are in blew figure, we can see that this method works as well as centralized training of segnet\noutput admm ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"55659a376b679559dd0aada49a1e57c4","permalink":"https://amirhosein-mesbah.github.io/project/federated/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/federated/","section":"project","summary":"Image segmentation by using Federated Learning for autonomous driving application.","tags":["Deep Learning","past"],"title":"Federated Learning on Semantic Segmentation task (FedAVG, FedADMM)","type":"project"},{"authors":null,"categories":null,"content":"An implementation of the paper entitled ‚ÄúGenerative Cooperative Net for Image Generation and Data Augmentation‚Äù by Qiangeng Xu et al, as a part of the final project for the course Deep Learning at the spring semester of 2021, University of Tehran.\nDataSet In this project we‚Äôve use two different datasets:\nKarolinska Directed Emotional Faces QMNIST Goals This projects goal is to build a neural network to\nGenerat images of faces (for KDEF dataset) Generat images of hadwritten number (for QMNIST dataset) Create a new augmentation tool: After training the GCN network and combining the identity features of two people with a ratio of 0.5, new images can be produced Training With respect to different goals of hour network we train it on two different datasets as mentioned above. The input of networ for these datasets is different.\nInput of Network for KDEF dataset a one-hot encoded vector for identity of the image (with length of 70) a one-hot encoded vector for face expression of the image (with length of 4) a one-hot encoded vector for transformation of the number (with length of 8) an image with size of 28*28 Input of Network for KDEF dataset a one-hot encoded vector for number of the image (with length of 10) a one-hot encoded vector for color the number (with length of 3 for R, G and B) a one-hot encoded vector for transformation of the image (with length of 8) an image with size of 158*158 Model Our proposed model has two modules:\nGenerator: generate image with an MSE loss Classifier: classifies the generated image of generator. In this structure, the generator and the classifier have goals in the same direction and they are trying to increase the quality of the produced images by working together. The Architecture of model is shown below\nmodel Results Here we have the results for our metioned tasks. right column of each image is model output.\nGenerating images of faces (for KDEF dataset)\nmodel output faces Generating images of handwritten numbers (for QMNIST dataset)\nmodel output numbers Create a new augmentation tool\nmodel output augmentation Team Members Farhood Etaati Amir Mesbah ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3a2062beed732abd7c6a78b27fbe8560","permalink":"https://amirhosein-mesbah.github.io/project/gcn/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/gcn/","section":"project","summary":"A combination of an image generator and a classifier succeeds to generate images.","tags":["Deep Learning","past"],"title":"Generative Cooperative Network","type":"project"},{"authors":null,"categories":null,"content":"Image Captioning is one of the most fantastic applications of Deep Learning which uses multi-modal data (image and text) to generate captions for each given image. In This project, I use PyTorch to implement an image captioning task using ResNet Network architecture for creating embeddings for images and LSTMs for generating captions for each image. This project is an implementation of paper entitled ‚Äúimage captioning‚Äù by Vikram Mullachery et al.\nDataSet In this project I‚Äôve used ‚Äòflickr8k‚Äô dataset for training and evaluation of the network.\nPreProcessing multiple methods applied on dataset to preprocess the dataset are:\nResizeing and Normalization of images Creating Dictioanry with respect to captions of each image two training data samples are shown below training sample 1 training sample 2 Training I consider three different architectures and conditions for training:\nfreezed ResNet (except last layer) for generating image embeddings (transfer learning and fine tuning) and LSTM for Caption generation Unfreezed Resnet and LSTM for Caption generation Bi-LSTM for Caption generation loss function of these three configurations are shown below\nloss during training Results some results for the second configuration (Unfreezed ResNet) are shown below output 1 output 2 output 3 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7e80cce7bf628dfa52261bd4021466ec","permalink":"https://amirhosein-mesbah.github.io/project/image_captioning/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/image_captioning/","section":"project","summary":"Combining Image embeddings from Resnet and text embeddings from LSTM to generate captions for images.","tags":["Deep Learning","past"],"title":"Image Captioning","type":"project"},{"authors":null,"categories":null,"content":"In this Prject, I‚Äôve implemented several models of Neural Dynamic models of single cell and population models with python.\nHodgkin‚ÄìHuxley model The Hodgkin‚ÄìHuxley model is one of the most recognized models in computational neuroscience. Describing the propagation of an action potential along the squid‚Äôs giant axon, the HH model states that the axon carries three ionic currents\nleaky-integrate-and-fire The leaky integrate and fire model which can be traced back to Louis Lapicque, is an idealization of a neuron having ohmic leakage current and a number of voltage-gated currents that are completely deactivated at rest.\nMorris-Lecar The Morris-Lecar model is a two-dimensional ‚Äúreduced‚Äù excitation model applicable to systems having two noninactivating voltage-sensitive conductances (one voltage variable and one gating variable). The original form of the model employed an instantaneously responding voltage-sensitive $Ca^{2+}$ conductance for excitation and a delayed voltage-dependent $K^{+}$ conductance for recovery. The model has three channels: a potassium channel, a leak, and a calcium channel. In the simplest version of the model, the calcium current depends instantaneously on the voltage.\nWilson-Cowan The Wilson-Cowan model is a powerful yet simple model that describes the interactions between two populations of excitatory and inhibitory neurons. This model is capable of analyzing neural hysteresis phenomena related to binocular vision and is used as a canonical model of visual cortical activity.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b354b8c20951b12180f9429c4a31d573","permalink":"https://amirhosein-mesbah.github.io/project/neural_dynamics/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/neural_dynamics/","section":"project","summary":"Investigating the role of the parameters in biological models of neurons.","tags":["Neuroscience","past"],"title":"Implementing multiple Neural Dynamic models of single cell and population models","type":"project"},{"authors":null,"categories":null,"content":"This Project is a Python Implementation of a paper entitled ‚ÄúA Neuro‚Äëcomputational Account of Arbitration between Choice Imitation and Goal Emulation during Human Observational Learning‚Äù by Caroline J. Charpentier et al. Data of participants in the task is provided by the authors. I used this data to Implement the models that are introduced in the paper to investigate the role of Imitation and emulation in our Daily Decision Making.\nResults After Implementing the models of paper, the results are as shown in the table below\nClass Model Out of Sample Accuracy% Emulation Inference 1 49,62 Emulation Inference 2 - Imitation RL 3 51,37 Imitation RL 4 53,88 Emulation RL 5 52,16 Emulation RL 6 52,63 Arbitration 7 54,63 Arbitration 8 - Due to the results best model is Arbitration model.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2eebcfc72645bfd5b21a667a22d0aba7","permalink":"https://amirhosein-mesbah.github.io/project/imitation_emulation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/imitation_emulation/","section":"project","summary":"Answer the question when our brain decides to imitate or emulate.","tags":["Neuroscience","past"],"title":"Investigating the role of Imitation and Emulation in Decision Making","type":"project"},{"authors":null,"categories":null,"content":"Machine Translation using Deep Learning is one of the popular tasks in NLP. With the introduction of Transformers by Google this kind of tasks entered a new era. This project is a Pytorch Implementation of ‚ÄúAttention is all you need‚Äù Paper by Ashish Vaswani et al. The Encoder Module is implemented from Scratch and the Decoder module is the decoder of pytorch.\nmodel Dataset In this project I use the dataset of Computational Audio-Vision Lab for training model.\nPreProcession Several preprocessing is applied to clean data and make it ready for training like:\ncreating dictionary removing infrequent tokens adding tokens like , , handleing persian unicodes and also I use two different methods for tokenization:\ntokenizing with NLTK and regex Byte Pair Encoding Training I‚Äôve used a model with 3 layers of encoder and 3 layers of decoder to train a translator! and also i need to mention that we have 3 kinds of models:\nmodel with NLTK Tokenizer without with layer normalization model with Byte Pair Encoding withiut with layer normalization model with layer normalization and NLTK tokenizer Results after 8 hours training the results of the mean NIST and mean Blue Score for first (best) model is given in the table below:\nMean corpus Blue score Mean corpus NIST score 14,63% 1,95 Also some translation examples (from English to Persian) is shown in the below table:\nEnglish Persian (translation of model) hello , do we drive together to Hanover on the twenty-eighth of March ? ÿ≥ŸÑÿßŸÖ . ŸÖÿß ÿØÿ± ŸÖÿßÿ±ÿ≥ ÿ®ÿß €å⁄©ÿØ€å⁄Øÿ± ÿ®Ÿá ŸáÿßŸÜŸàŸàÿ± ÿ≠ÿ±⁄©ÿ™ ÿÆŸàÿßŸá€åŸÖ ⁄©ÿ±ÿØ ? it is more comfortable by train . ŸÇÿ∑ÿßÿ± ÿ±ÿßÿ≠ÿ™ ÿ™ÿ± ÿßÿ≥ÿ™ a good idea . then we will meet at the airport tomorrow . Ÿæÿ≥ ŸÅÿ±ÿØÿß ŸáŸÖÿØ€å⁄Øÿ± ÿ±ÿß ÿØÿ± ŸÅÿ±ŸàÿØ⁄ØÿßŸá ŸÖŸÑÿßŸÇÿßÿ™ ÿÆŸàÿßŸá€åŸÖ ⁄©ÿ±ÿØ what is planned for the evening ? ÿ®ÿ±ŸÜÿßŸÖŸá ÿ±€åÿ≤€å ÿ®ÿ±ÿß€å ÿπÿµÿ± ⁄Ü€åÿ≥ÿ™ ? in any case a cheap hotel . ÿØÿ± Ÿáÿ± ÿµŸàÿ±ÿ™ ÿßÿ±ÿ≤ÿßŸÜ ŸÇ€åŸÖÿ™ ÿØÿ± Ÿáÿ± ÿµŸàÿ±ÿ™ ÿßÿ±ÿ≤ÿßŸÜ . I prefer the plane . ŸÖŸÜ ŸáŸàÿßŸæ€åŸÖÿß ÿ±ÿß ÿ™ÿ±ÿ¨€åÿ≠ ŸÖ€åÿØŸáŸÖ . ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"446089810b4cc21463d611cee1515bfd","permalink":"https://amirhosein-mesbah.github.io/project/machine_translation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/machine_translation/","section":"project","summary":"Taking advantage of transformers to build an English to Persian Translator.","tags":["Deep Learning","past"],"title":"Machine translation with transformers (English to Persian)","type":"project"},{"authors":null,"categories":null,"content":"In this Project, we Implement a Forest Environment which in fires take place and our agents‚Äô goal is to stop the fire and save the forest. This Implementation is s part of the final project for the course Interactive Learning in the Autumn semester of 2022, University of Tehran.\nEnvironment Environemnt Elements of Environment:\nForest: Green Area Areas without Tree: Brown Area Burnt forest: Black Area Drone Agents: Purple Squares Fire: Red Squares Houses: Blue Square Station of Drones: Yellow Square In this environment, the fire spreads according to the wind and the defined probability of transition, and the task of the agents is to prevent the spread of fire by working together. One of the challenging problems of this environment is that it is non-stationary.\nTraining Each Agent is training with a Double-DQN and agents have the ability to communicate with each other in a certain environmental range for better coordination with a level of hierarchy in swarm intelligence.\nResults Due to a Shortage of Computational power, we succeed to train the agents for just four hours. One of the test episodes after training is shown in the video below\nRun Team members: Banafsheh Karimian Erfan Mirzaei ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f4fc320c2651a054bb23be9c1d4d3e35","permalink":"https://amirhosein-mesbah.github.io/project/multi_agent_rl/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/multi_agent_rl/","section":"project","summary":"Train a multi agent system of drones to prevent fires in an implemented forest environment.","tags":["Reinforcement Learning","past"],"title":"Multi-Agent Deep Reinforcement Learning for Fighting Forest Fires","type":"project"},{"authors":null,"categories":null,"content":"In this Project I‚Äôve used Bandit Algorithms to solve the Problem of Routing for the graph below:\nNetwork Graph Algorithms: For solving this task I‚Äôve used different algorithms for multi-armed bandit problems like UCB and Epsilon-Greedy. each route in the network is considered an arm for a multi-armed bandit and each arm has its own stochastic reward due to the delays that may occur during the route.\nResults Below you can see the average reward for the epsilon greedy algorithm and the percentage of optimal action selection for UCB and epsilon greedy algorithms:\nthe average reward for epsilon greedy algorithm average reward for epsilon greedy the percentage of optimal action selection for UCB and epsilon greedy Optimal action selection ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ffe229fa1dfb29cd285e6e1ccebc276c","permalink":"https://amirhosein-mesbah.github.io/project/routing_bandits/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/routing_bandits/","section":"project","summary":"Implementing multi-armed bandit algorithms like UCB and epsilon greedy for network routing application.","tags":["Reinforcement Learning","past"],"title":"Network routing with multi-armed bandit algorithms","type":"project"},{"authors":null,"categories":null,"content":"This Project is an implementation of paper entilted ‚ÄúRelation Classification via Recurrent Neural Network‚Äù by Dongxu Zhang et al. I use pytorch for implementing this project. After Preprocessing text data and extracting labels for each datapoint, I use bi-LSTM Network with three different conditions to train the network.\nPreProcessing creating dictionary with respect to tokens encoding labels Training I use 3 Configurations for Training a bi-LSTM Network:\nbi-LSTM using Glove Embeddings (pre-trained) bi-LSTM using random initialized embedding bi-LSTM using random initialized embedding with addition of max and average pooling layers loss and accuracy during training are shown below\nloss accuracy results the confusion matrix for third configuration on test data is shown below confusion matrix ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d9032e689dc4d89b750a84ba79ab7fa1","permalink":"https://amirhosein-mesbah.github.io/project/relation_extraction/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/relation_extraction/","section":"project","summary":"Extracting Relations from Sentences using LSTMs.","tags":["Deep Learning","past"],"title":"Relation Extraction Via Reccurent Neural Neworks","type":"project"},{"authors":null,"categories":null,"content":"Semantic Segmentation is one of the classic tasks of Computer vision and deep learning. in this project I‚Äôve implemented SegNet. the Network which was introduced in the paper entitled ‚ÄúSegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation‚Äù by Vijay Badrinarayanan et al. I‚Äôve used Pytorch framework for this implementation.\nPreProcessing multiple preprocessing that has been done on images to be ready for training are:\nresizing images creating codecs (labels) for each pixels one hot encoding for label of pixels Training after deviding data to 3 sets of train, validation and test, the SegNet Network is trained with proposed data for 2 cases (network with batch normalization and network without bach normalization. Amount of loss function during trainig is shown below loss of network during training Results results for segmentation of test images for the network without batch normalization is shown below output of network for segmentation ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cca02735817a3dd9b39a4b04ef8d72d5","permalink":"https://amirhosein-mesbah.github.io/project/semantic_segmentation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/semantic_segmentation/","section":"project","summary":"using Deep Neural Networks for segmenting images of Camvid dataset.","tags":["Deep Learning","past"],"title":"Semantic segmentation with Segnet","type":"project"},{"authors":null,"categories":null,"content":"In this project, I‚Äôve used Apache Spark for NLP and Machine Learning tasks.\nSpark for Machine Learning model In this Task, I‚Äôve used spark ML to build an mlp model and apply a multi-label classification on a `spark data frame. After Preprocessing Data and creating a column for labels, Standardization and PCA are applied to data respectfully.\nResults The results of training a mlp model on the proposed dataset are shown in the table below:\nModel Test Accuracy Test Recall Test Precision MLP 96,01% 96,01% 92,19% Spark for NLP For this task, I downloaded the Les Mis√©rables book and created a spark dataframe with sentences from the book. After that, I created the bigram and trigram of the prepared data frame and compute the count of each bigram and trigram. for the last part, I implemented a logistic regression to see if there is any relationship between the length of words in bigram or trigram.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"314cd62367ddf3c335b5e406b071ea73","permalink":"https://amirhosein-mesbah.github.io/project/spark/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/spark/","section":"project","summary":"multiple machine learning task like PCA, classification with mlp, Regression and creating bigram and trigram.","tags":["BigData","past"],"title":"Using Apache Spark for NLP and Machine Learning tasks","type":"project"}]